{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "from mlxtend.frequent_patterns import apriori, association_rules \n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"h2Data.csv\"\n",
    "dataset = pd.read_csv(csv_file, names = ['T1','T2', \"T3\", \"T4\", \"T5\"])\n",
    "\n",
    "# Convert csv file to nested array so mlxtend library can encode it\n",
    "dataset = dataset.replace({np.nan: None})\n",
    "\n",
    "datalist = dataset.values.tolist()\n",
    "# Library requires we remove None values from arrays\n",
    "cleaned_data = [[x for x in sublist if x is not None] for sublist in datalist]\n",
    "\n",
    "# Resulting data is cleaned_data\n",
    "# cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1.0    2.0    3.0    4.0    5.0    6.0    7.0    8.0    9.0    10.0  ...  \\\n",
      "0  False  False  False  False   True   True  False  False  False  False  ...   \n",
      "1  False  False  False  False  False   True  False  False  False  False  ...   \n",
      "2  False  False  False  False  False  False  False  False   True  False  ...   \n",
      "3  False  False  False  False  False  False   True  False  False  False  ...   \n",
      "\n",
      "    41.0   42.0   43.0   44.0   45.0   46.0   47.0   48.0   49.0   50.0  \n",
      "0  False  False  False  False  False   True  False  False  False  False  \n",
      "1  False  False  False  False  False  False  False  False  False  False  \n",
      "2  False  False  False  False  False  False  False  False  False  False  \n",
      "3   True  False  False  False  False  False  False  False  False  False  \n",
      "\n",
      "[4 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(cleaned_data).transform(cleaned_data)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "print(df.head(4))\n",
    "\n",
    "# Result is a sparse dataframe showing the items purchased for each transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated support threshold: 0.09516258196404048\n",
      "   support itemsets\n",
      "0    0.094    (1.0)\n",
      "1    0.107    (2.0)\n",
      "2    0.110    (3.0)\n",
      "3    0.076    (4.0)\n",
      "4    0.103    (5.0)\n",
      "(88, 2)\n"
     ]
    }
   ],
   "source": [
    "# Find assoiation rules with at least 2 antecedents, min confidence, min support, min lift\n",
    "\n",
    "# defining thresholds based on lab 1 advice:\n",
    "basket_size = 5\n",
    "item_count = 50\n",
    "support_threshold = 1 - math.exp((-1 * basket_size) / item_count)\n",
    "print(f\"calculated support threshold: {support_threshold}\")\n",
    "support_threshold = 0.015\n",
    "\n",
    "support_confidence_proportion = 0.5\n",
    "confidence_threshold = support_confidence_proportion * support_threshold\n",
    "lift_threshold = 1.1\n",
    "\n",
    "# Generate frequent_items sets based on min_support threshold\n",
    "frequent_itemsets = apriori(df, min_support=support_threshold, use_colnames=True)\n",
    "print(frequent_itemsets.head(5))\n",
    "print(frequent_itemsets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0       (1.0)      (45.0)               0.094               0.107    0.017   \n",
      "1      (45.0)       (1.0)               0.107               0.094    0.017   \n",
      "2       (8.0)       (2.0)               0.107               0.107    0.018   \n",
      "3       (2.0)       (8.0)               0.107               0.107    0.018   \n",
      "4      (33.0)       (2.0)               0.107               0.107    0.017   \n",
      "\n",
      "   confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0    0.180851  1.690197  0.006942    1.090156       0.450721  \n",
      "1    0.158879  1.690197  0.006942    1.077133       0.457282  \n",
      "2    0.168224  1.572190  0.006551    1.073607       0.407553  \n",
      "3    0.168224  1.572190  0.006551    1.073607       0.407553  \n",
      "4    0.158879  1.484846  0.005551    1.061678       0.365654  \n",
      "(76, 10)\n"
     ]
    }
   ],
   "source": [
    "# Apply confidence threhsold\n",
    "confidence_df = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "print(confidence_df.head(5))\n",
    "print(confidence_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  antecedents consequents  support  confidence      lift\n",
      "0       (1.0)      (45.0)    0.017    0.180851  1.690197\n",
      "1      (45.0)       (1.0)    0.017    0.158879  1.690197\n",
      "2       (8.0)       (2.0)    0.018    0.168224  1.572190\n",
      "3       (2.0)       (8.0)    0.018    0.168224  1.572190\n",
      "4      (33.0)       (2.0)    0.017    0.158879  1.484846\n",
      "(74, 5)\n"
     ]
    }
   ],
   "source": [
    "# Apply lift threshold on the confidence threshold df\n",
    "lift_confidence_df = confidence_df[(confidence_df['lift'] >= lift_threshold)]\n",
    "# Drop accessory columns for clarity\n",
    "lift_confidence_df = lift_confidence_df.drop(columns=[\"conviction\", \"zhangs_metric\", \"leverage\", \"antecedent support\", \"consequent support\"])\n",
    "print(lift_confidence_df.head(5))\n",
    "print(lift_confidence_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12195121951219512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift_confidence_df[\"confidence\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. By trial and error, what are the values of the minimum support, minimum confidence, and minimum lift for which the number of interesting association rules is between 1 and 2 times the number of items?\n",
    "\n",
    "A: When support_threshold = 0.015, confidence threshold is 0.0075 (proportionally half of support_threshold), and lift_threshold = 1.1, we are left with 74 association rules which is between the range of 1 and 2 times the number of items (50 and 100)\n",
    "\n",
    "Q2. What relationship between these variables keeps the number of interesting association rules in this range?\n",
    "I found that the lowest confidence of the 74 association rules was 0.1219, as shown above. This is significantly greater than the current confidence threshold of 0.0075. \n",
    "\n",
    "Support seems to be the main driver of keeping the number of association rules in this range. I say this because when the support threshold is set to 0.015, only 88 associtation frequent itemsets are derived, before the confidence and lift thresholds are even applied. Upon applying the confidence threshold that is proportionally 50% of the support, and a lift threshold of 1.1, the number of rules drops from 88 to 74. Manipulating the support threshold selects the number of itemsets that are to be filtered by confidence and lift, and ultimately drives the number of resulting association rules. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   antecedents consequents  support  confidence      lift  count\n",
      "34       (9.0)      (37.0)    0.019    0.166667  1.355014   19.0\n",
      "35      (37.0)       (9.0)    0.019    0.154472  1.355014   19.0\n",
      "2        (8.0)       (2.0)    0.018    0.168224  1.572190   18.0\n",
      "3        (2.0)       (8.0)    0.018    0.168224  1.572190   18.0\n",
      "46      (35.0)      (14.0)    0.018    0.151261  1.609154   18.0\n",
      "..         ...         ...      ...         ...       ...    ...\n",
      "48      (41.0)      (20.0)    0.015    0.138889  1.286008   15.0\n",
      "49      (20.0)      (41.0)    0.015    0.138889  1.286008   15.0\n",
      "50      (43.0)      (20.0)    0.015    0.156250  1.446759   15.0\n",
      "51      (20.0)      (43.0)    0.015    0.138889  1.446759   15.0\n",
      "75      (43.0)      (48.0)    0.015    0.156250  1.717033   15.0\n",
      "\n",
      "[76 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#Q3:\n",
    "\n",
    "# Find assoiation rules with at least 2 antecedents, min confidence, min support, min lift\n",
    "\n",
    "support_threshold = 0.015\n",
    "confidence_threshold = 0.01\n",
    "lift_threshold = 1\n",
    "\n",
    "# Genertae frequent_itemsets then apply thresholds\n",
    "frequent_itemsets_2 = apriori(df, min_support=support_threshold, use_colnames=True)\n",
    "\n",
    "# Apply confidence threhsold\n",
    "confidence_df_2 = association_rules(frequent_itemsets_2, metric=\"confidence\", min_threshold=confidence_threshold)\n",
    "\n",
    "# Apply lift threshold on the confidence threshold df\n",
    "lift_confidence_df_2 = confidence_df[(confidence_df_2['lift'] >= lift_threshold)]\n",
    "# Drop accessory columns for clarity\n",
    "lift_confidence_df_2 = lift_confidence_df_2.drop(columns=[\"conviction\", \"zhangs_metric\", \"leverage\", \"antecedent support\", \"consequent support\"])\n",
    "\n",
    "# Adding count column\n",
    "transactions = 1000\n",
    "lift_confidence_df_2[\"count\"] = lift_confidence_df_2[\"support\"] * transactions\n",
    "#Print result\n",
    "lift_confidence_df_2 = lift_confidence_df_2.sort_values(by=[\"count\"], ascending=False)\n",
    "print(lift_confidence_df_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 6)\n",
      "   antecedents consequents  support  confidence      lift  count\n",
      "73      (42.0)      (41.0)    0.017    0.186813  1.729752   17.0\n",
      "72      (41.0)      (42.0)    0.017    0.157407  1.729752   17.0\n",
      "75      (43.0)      (48.0)    0.015    0.156250  1.717033   15.0\n",
      "74      (48.0)      (43.0)    0.015    0.164835  1.717033   15.0\n",
      "20      (18.0)       (6.0)    0.015    0.172414  1.690331   15.0\n",
      "21       (6.0)      (18.0)    0.015    0.147059  1.690331   15.0\n",
      "1       (45.0)       (1.0)    0.017    0.158879  1.690197   17.0\n",
      "0        (1.0)      (45.0)    0.017    0.180851  1.690197   17.0\n",
      "44      (11.0)      (23.0)    0.015    0.159574  1.628311   15.0\n",
      "45      (23.0)      (11.0)    0.015    0.153061  1.628311   15.0\n",
      "47      (14.0)      (35.0)    0.018    0.191489  1.609154   18.0\n",
      "46      (35.0)      (14.0)    0.018    0.151261  1.609154   18.0\n",
      "10       (3.0)      (15.0)    0.015    0.136364  1.585624   15.0\n",
      "11      (15.0)       (3.0)    0.015    0.174419  1.585624   15.0\n",
      "3        (2.0)       (8.0)    0.018    0.168224  1.572190   18.0\n",
      "2        (8.0)       (2.0)    0.018    0.168224  1.572190   18.0\n",
      "69      (45.0)      (36.0)    0.016    0.149533  1.557632   16.0\n",
      "68      (36.0)      (45.0)    0.016    0.166667  1.557632   16.0\n",
      "13       (3.0)      (26.0)    0.016    0.145455  1.531100   16.0\n",
      "12      (26.0)       (3.0)    0.016    0.168421  1.531100   16.0\n",
      "14      (42.0)       (3.0)    0.015    0.164835  1.498501   15.0\n",
      "15       (3.0)      (42.0)    0.015    0.136364  1.498501   15.0\n",
      "4       (33.0)       (2.0)    0.017    0.158879  1.484846   17.0\n",
      "5        (2.0)      (33.0)    0.017    0.158879  1.484846   17.0\n",
      "39      (23.0)      (10.0)    0.016    0.163265  1.484230   16.0\n",
      "38      (10.0)      (23.0)    0.016    0.145455  1.484230   16.0\n",
      "25       (6.0)      (34.0)    0.016    0.156863  1.452433   16.0\n",
      "24      (34.0)       (6.0)    0.016    0.148148  1.452433   16.0\n",
      "16       (8.0)       (5.0)    0.016    0.149533  1.451774   16.0\n",
      "17       (5.0)       (8.0)    0.016    0.155340  1.451774   16.0\n",
      "50      (43.0)      (20.0)    0.015    0.156250  1.446759   15.0\n",
      "51      (20.0)      (43.0)    0.015    0.138889  1.446759   15.0\n",
      "22       (6.0)      (31.0)    0.015    0.147059  1.441753   15.0\n",
      "23      (31.0)       (6.0)    0.015    0.147059  1.441753   15.0\n",
      "40      (10.0)      (34.0)    0.017    0.154545  1.430976   17.0\n",
      "41      (34.0)      (10.0)    0.017    0.157407  1.430976   17.0\n",
      "29      (21.0)       (9.0)    0.016    0.160000  1.403509   16.0\n",
      "28       (9.0)      (21.0)    0.016    0.140351  1.403509   16.0\n",
      "57      (31.0)      (24.0)    0.016    0.156863  1.400560   16.0\n",
      "56      (24.0)      (31.0)    0.016    0.142857  1.400560   16.0\n",
      "31      (28.0)       (9.0)    0.015    0.159574  1.399776   15.0\n",
      "30       (9.0)      (28.0)    0.015    0.131579  1.399776   15.0\n",
      "62      (49.0)      (34.0)    0.016    0.149533  1.384562   16.0\n",
      "63      (34.0)      (49.0)    0.016    0.148148  1.384562   16.0\n",
      "52      (24.0)      (23.0)    0.015    0.133929  1.366618   15.0\n",
      "53      (23.0)      (24.0)    0.015    0.153061  1.366618   15.0\n",
      "36      (10.0)      (21.0)    0.015    0.136364  1.363636   15.0\n",
      "37      (21.0)      (10.0)    0.015    0.150000  1.363636   15.0\n",
      "34       (9.0)      (37.0)    0.019    0.166667  1.355014   19.0\n",
      "35      (37.0)       (9.0)    0.019    0.154472  1.355014   19.0\n"
     ]
    }
   ],
   "source": [
    "#Q4:\n",
    "top_50_rules = lift_confidence_df_2.sort_values(by=[\"lift\"], ascending=False).head(50)\n",
    "print(top_50_rules.shape)\n",
    "print(top_50_rules)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
